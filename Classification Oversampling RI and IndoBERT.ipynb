{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyOxf4gtbN48vC+S7wAo5EVP"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":28,"metadata":{"id":"eogwu2oVyIyi","executionInfo":{"status":"ok","timestamp":1702875896757,"user_tz":-420,"elapsed":471,"user":{"displayName":"Rahmat Hendrawan","userId":"13136351621992479567"}}},"outputs":[],"source":["import torch\n","\n","from transformers import BertTokenizer\n","\n","import statistics\n","\n","from torch.utils.data import TensorDataset, random_split\n","from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n","\n","from transformers import BertForSequenceClassification, AdamW, BertConfig\n","from transformers import BertModel\n","\n","from transformers import AdamW\n","from transformers import get_linear_schedule_with_warmup\n","\n","import pandas as pd\n","import numpy as np\n","\n","from sklearn.metrics import classification_report, confusion_matrix,accuracy_score,precision_score,recall_score\n","\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import statistics\n","import time\n","import pickle"]},{"cell_type":"code","source":["from google.colab import drive"],"metadata":{"id":"hF56IcbBKkBz","executionInfo":{"status":"ok","timestamp":1702875898856,"user_tz":-420,"elapsed":3,"user":{"displayName":"Rahmat Hendrawan","userId":"13136351621992479567"}}},"execution_count":29,"outputs":[]},{"cell_type":"code","source":["import torch\n","if torch.cuda.is_available():\n","    device = torch.device(\"cuda\")\n","    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n","    print('We will use the GPU:', torch.cuda.get_device_name(0))\n","\n","else:\n","    print('No GPU available, using the CPU instead.')\n","    device = torch.device(\"cpu\")"],"metadata":{"id":"r2PvSqUeyMQA","executionInfo":{"status":"ok","timestamp":1702875899564,"user_tz":-420,"elapsed":7,"user":{"displayName":"Rahmat Hendrawan","userId":"13136351621992479567"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"be40d4e3-2994-48fb-d6d7-4c4399226e53"},"execution_count":30,"outputs":[{"output_type":"stream","name":"stdout","text":["There are 1 GPU(s) available.\n","We will use the GPU: Tesla T4\n"]}]},{"cell_type":"code","source":["drive.mount('/content/gdrive')"],"metadata":{"id":"zhe0dfii1atL","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1702876337207,"user_tz":-420,"elapsed":3387,"user":{"displayName":"Rahmat Hendrawan","userId":"13136351621992479567"}},"outputId":"46194dff-56ef-4f96-ef13-3f25f3dace19"},"execution_count":53,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["data_train = pd.read_excel('/content/gdrive/MyDrive/Colab Notebooks/Latihan/Data Augmentation NLP/data_train_edari.xlsx')\n","data_test = pd.read_excel('/content/gdrive/MyDrive/Colab Notebooks/Latihan/Data Augmentation NLP/data_test.xlsx')"],"metadata":{"id":"raXwat5eKwTv","executionInfo":{"status":"ok","timestamp":1702876339762,"user_tz":-420,"elapsed":1212,"user":{"displayName":"Rahmat Hendrawan","userId":"13136351621992479567"}}},"execution_count":54,"outputs":[]},{"cell_type":"code","source":["X_train = data_train['Kalimat_prep']\n","y_train = data_train['label'] - 1\n","\n","X_test = data_test['Kalimat_prep']\n","y_test = data_test['label'] - 1"],"metadata":{"id":"CNm3shjNLDpg","executionInfo":{"status":"ok","timestamp":1702876346323,"user_tz":-420,"elapsed":5,"user":{"displayName":"Rahmat Hendrawan","userId":"13136351621992479567"}}},"execution_count":55,"outputs":[]},{"cell_type":"code","source":["torch.cuda.empty_cache()"],"metadata":{"id":"awGVdaJ2LMTW","executionInfo":{"status":"ok","timestamp":1702876346323,"user_tz":-420,"elapsed":3,"user":{"displayName":"Rahmat Hendrawan","userId":"13136351621992479567"}}},"execution_count":56,"outputs":[]},{"cell_type":"code","source":["print('Loading BERT tokenizer...')\n","tokenizer = BertTokenizer.from_pretrained(\"indobenchmark/indobert-base-p1\", do_lower_case=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"myD9eauZLNnO","executionInfo":{"status":"ok","timestamp":1702876347011,"user_tz":-420,"elapsed":2,"user":{"displayName":"Rahmat Hendrawan","userId":"13136351621992479567"}},"outputId":"53cd086a-cab4-4b2e-9e08-5a4625fb19b4"},"execution_count":57,"outputs":[{"output_type":"stream","name":"stdout","text":["Loading BERT tokenizer...\n"]}]},{"cell_type":"code","source":["sentences = X_train.values\n","labels = y_train.astype(int).values\n","\n","test_sentences = X_test.values"],"metadata":{"id":"a73eOTtnLSSV","executionInfo":{"status":"ok","timestamp":1702876348028,"user_tz":-420,"elapsed":4,"user":{"displayName":"Rahmat Hendrawan","userId":"13136351621992479567"}}},"execution_count":58,"outputs":[]},{"cell_type":"code","source":["sent_length = []\n","\n","# For every sentence...\n","for sent in sentences:\n","    # Tokenize the text and add `[CLS]` and `[SEP]` tokens.\n","    token_ids = tokenizer.encode(sent, add_special_tokens=True)\n","    sent_length.append(len(token_ids))\n","\n","print('Average length = ', sum(sent_length)/len(sent_length))\n","print('Median length = ', statistics.median(sent_length))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fxI6VWaMLZL2","executionInfo":{"status":"ok","timestamp":1702876352114,"user_tz":-420,"elapsed":3395,"user":{"displayName":"Rahmat Hendrawan","userId":"13136351621992479567"}},"outputId":"0f378039-7f89-4a13-95e6-deb8b50be9ab"},"execution_count":59,"outputs":[{"output_type":"stream","name":"stdout","text":["Average length =  25.759841842874334\n","Median length =  19\n"]}]},{"cell_type":"code","source":["# Tokenize all of the sentences and map the tokens to their word IDs.\n","token_ids  = []\n","attention_masks = []\n","\n","# For every sentence...\n","for sent in sentences:\n","    encoded_dict = tokenizer.encode_plus(\n","                        sent,                      # Sentence to encode.\n","                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n","                        max_length = 40,           # Pad & truncate all sentences.\n","                        pad_to_max_length = True,\n","                        return_attention_mask = True,   # Construct attn. masks.\n","                        return_tensors = 'pt',     # Return pytorch tensors.\n","                   )\n","\n","    token_ids.append(encoded_dict['input_ids'])\n","    attention_masks.append(encoded_dict['attention_mask'])\n","\n","# Convert the lists into tensors.\n","token_ids  = torch.cat(token_ids, dim=0)\n","attention_masks = torch.cat(attention_masks, dim=0)\n","labels = torch.tensor(labels)\n","# labels = torch.nn.functional.one_hot(labels.to(torch.int64))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rZP0v3izLdF9","executionInfo":{"status":"ok","timestamp":1702876357453,"user_tz":-420,"elapsed":5341,"user":{"displayName":"Rahmat Hendrawan","userId":"13136351621992479567"}},"outputId":"684f6f69-ec4c-43de-c983-59581286dc48"},"execution_count":60,"outputs":[{"output_type":"stream","name":"stderr","text":["Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n"]}]},{"cell_type":"code","source":["# Print sentence 0, now as a list of IDs.\n","print('Original: ', sentences[0])\n","print('Token IDs:', token_ids[0])\n","print('Attention Masks:', attention_masks[0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wjFOoOp1L65F","executionInfo":{"status":"ok","timestamp":1702876357453,"user_tz":-420,"elapsed":3,"user":{"displayName":"Rahmat Hendrawan","userId":"13136351621992479567"}},"outputId":"f96c2ae0-c769-4a4e-efa5-22b7468e661d"},"execution_count":61,"outputs":[{"output_type":"stream","name":"stdout","text":["Original:  esia yang terlupakan gak kayak smartfren sih yang udah suport jaringan tidak kalo perusahaan gak ikuti jaman ya begini lah jadinya\n","Token IDs: tensor([    2,  1660,   102,    34, 14195,  1489,  5788, 10905,  1966,    34,\n","         2137,   888,   869,  1799,   119,  1686,   742,  1489,  5576,  4881,\n","          286,  6838,  1389,  9802,     3,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0])\n","Attention Masks: tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n"]}]},{"cell_type":"code","source":["# Tokenize all of the sentences and map the tokens to their word IDs.\n","test_token_ids  = []\n","test_attention_masks = []\n","\n","# For every sentence...\n","for test_sent in test_sentences:\n","    test_encoded_dict = tokenizer.encode_plus(\n","                        test_sent,                      # Sentence to encode.\n","                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n","                        max_length = 40,           # Pad & truncate all sentences.\n","                        pad_to_max_length = True,\n","                        return_attention_mask = True,   # Construct attn. masks.\n","                        return_tensors = 'pt',     # Return pytorch tensors.\n","                   )\n","\n","    test_token_ids.append(test_encoded_dict['input_ids'])\n","    test_attention_masks.append(test_encoded_dict['attention_mask'])\n","\n","# Convert the lists into tensors.\n","test_token_ids  = torch.cat(test_token_ids, dim=0)\n","test_attention_masks = torch.cat(test_attention_masks, dim=0)\n","test_labels = torch.tensor(y_test.astype(int).values)\n","# labels = torch.nn.functional.one_hot(labels.to(torch.int64))"],"metadata":{"id":"yq6zSgdSL-k-","executionInfo":{"status":"ok","timestamp":1702876360083,"user_tz":-420,"elapsed":490,"user":{"displayName":"Rahmat Hendrawan","userId":"13136351621992479567"}}},"execution_count":62,"outputs":[]},{"cell_type":"code","source":["# Combine the training inputs into a TensorDataset.\n","train_dataset = TensorDataset(token_ids, attention_masks, labels)\n","test_dataset = TensorDataset(test_token_ids, test_attention_masks, test_labels)\n"],"metadata":{"id":"B0DoSP5oMHzO","executionInfo":{"status":"ok","timestamp":1702876362407,"user_tz":-420,"elapsed":5,"user":{"displayName":"Rahmat Hendrawan","userId":"13136351621992479567"}}},"execution_count":63,"outputs":[]},{"cell_type":"code","source":["# For fine-tuning BERT on a specific task, the authors recommend a batch size of 16 or 32.\n","batch_size = 32\n","\n","# Create the DataLoaders for our training and validation sets.\n","# We'll take training samples in random order.\n","train_dataloader = DataLoader(\n","            train_dataset,  # The training samples.\n","            sampler = RandomSampler(train_dataset), # Select batches randomly\n","            batch_size = batch_size # Trains with this batch size.\n","        )\n","\n","# For test the order doesn't matter, so we'll just read them sequentially.\n","test_dataloader = DataLoader(\n","            test_dataset, # The test samples.\n","            sampler = SequentialSampler(test_dataset), # Pull out batches sequentially.\n","            batch_size = batch_size # Evaluate with this batch size.\n","        )"],"metadata":{"id":"5e7YnHXKMLcV","executionInfo":{"status":"ok","timestamp":1702876364409,"user_tz":-420,"elapsed":2,"user":{"displayName":"Rahmat Hendrawan","userId":"13136351621992479567"}}},"execution_count":64,"outputs":[]},{"cell_type":"code","source":["# Load BertForSequenceClassification, the pretrained BERT model with a single\n","# linear classification layer on top.\n","model = BertForSequenceClassification.from_pretrained(\n","    \"indobenchmark/indobert-base-p1\",\n","    num_labels = 3,\n","    output_attentions = False, # return attentions weights\n","    output_hidden_states = False, # returns all hidden-states\n",")\n","\n","model.cuda()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TAemHLqrMRLu","executionInfo":{"status":"ok","timestamp":1702876771411,"user_tz":-420,"elapsed":2874,"user":{"displayName":"Rahmat Hendrawan","userId":"13136351621992479567"}},"outputId":"75aa2979-84d3-4927-ea2a-805b7b0b7fc2"},"execution_count":76,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"execute_result","data":{"text/plain":["BertForSequenceClassification(\n","  (bert): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(50000, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0-11): 12 x BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (dropout): Dropout(p=0.1, inplace=False)\n","  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",")"]},"metadata":{},"execution_count":76}]},{"cell_type":"code","source":["optimizer = torch.optim.AdamW(model.parameters(),\n","                  lr = 1e-5,\n","                  eps = 1e-8\n","                )"],"metadata":{"id":"04FsNJWlMloz","executionInfo":{"status":"ok","timestamp":1702876771411,"user_tz":-420,"elapsed":4,"user":{"displayName":"Rahmat Hendrawan","userId":"13136351621992479567"}}},"execution_count":77,"outputs":[]},{"cell_type":"code","source":["epochs = 2\n","\n","# Total number of training steps is [number of batches] x [number of epochs].\n","# (Note that this is not the same as the number of training samples).\n","print('Jumlah batch :', len(train_dataloader))\n","total_steps = len(train_dataloader) * epochs\n","\n","# Create the learning rate scheduler.\n","scheduler = get_linear_schedule_with_warmup(optimizer,\n","                                            num_warmup_steps = 0, # Default value in run_glue.py\n","                                            num_training_steps = total_steps)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Gc5_i5n3MqSE","executionInfo":{"status":"ok","timestamp":1702876771411,"user_tz":-420,"elapsed":3,"user":{"displayName":"Rahmat Hendrawan","userId":"13136351621992479567"}},"outputId":"f8bd0522-4874-4a8e-f693-932e69973c8b"},"execution_count":78,"outputs":[{"output_type":"stream","name":"stdout","text":["Jumlah batch : 182\n"]}]},{"cell_type":"code","source":["def acc_score(y_pred,y_test):\n","    acc_count = (torch.log_softmax(y_pred, dim=1).argmax(dim=1) == y_test).sum().float() / float(y_test.size(0))\n","    return acc_count"],"metadata":{"id":"YFEa4qX7Mtwv","executionInfo":{"status":"ok","timestamp":1702876771411,"user_tz":-420,"elapsed":2,"user":{"displayName":"Rahmat Hendrawan","userId":"13136351621992479567"}}},"execution_count":79,"outputs":[]},{"cell_type":"code","source":["EPOCHS = epochs\n","\n","loss_values = []\n","y_true_test=[]\n","y_pred_test = []\n","\n","total_step = len(train_dataloader)\n","\n","for epoch in range(EPOCHS):\n","    start = time.time()\n","    model.train()\n","    torch.set_grad_enabled(True)\n","\n","    total_train_loss = 0\n","    total_train_acc  = 0\n","    for batch_idx, (token_ids, attention_masks, labels) in enumerate(train_dataloader):\n","        optimizer.zero_grad()\n","        b_input_ids = token_ids.to(device)\n","        b_input_mask = attention_masks.to(device)\n","        labels = labels.to(device)\n","\n","        loss, prediction = model(b_input_ids,\n","                                token_type_ids=None,\n","                                attention_mask=b_input_mask,\n","                                labels=labels).values()\n","\n","#         print(batch_idx)\n","#         print(labels)\n","        acc = acc_score(prediction, labels)\n","\n","        loss.backward()\n","        optimizer.step()\n","\n","        total_train_loss += loss.item()\n","        total_train_acc  += acc.item()\n","\n","    avg_train_loss = total_train_loss / len(train_dataloader)\n","    loss_values.append(avg_train_loss)\n","\n","    train_acc  = total_train_acc/len(train_dataloader)\n","    train_loss = total_train_loss/len(train_dataloader)\n","    model.eval()\n","    torch.set_grad_enabled(False)\n","\n","    total_test_acc  = 0\n","    total_test_loss = 0\n","    with torch.no_grad():\n","        for batch_idx, (token_ids, attention_masks, labels) in enumerate(test_dataloader):\n","            optimizer.zero_grad()\n","\n","            b_input_ids = token_ids.to(device)\n","            b_input_mask = attention_masks.to(device)\n","            labels = labels.to(device)\n","\n","            loss, prediction = model(b_input_ids,\n","                                  token_type_ids=None,\n","                                  attention_mask=b_input_mask,\n","                                  labels=labels).values()\n","\n","            acc = acc_score(prediction, labels)\n","\n","            logits = prediction\n","            logits = logits.detach().cpu().numpy()\n","            b_labels = labels.to('cpu').numpy()\n","\n","            y_pred_test.append(logits)\n","            y_true_test.append(b_labels)\n","\n","            total_test_loss += loss.item()\n","            total_test_acc  += acc.item()\n","\n","    test_acc  = total_test_acc/len(test_dataloader)\n","    test_loss = total_test_loss/len(test_dataloader)\n","    end = time.time()\n","    hours, rem = divmod(end-start, 3600)\n","    minutes, seconds = divmod(rem, 60)\n","\n","    print(f'Epoch {epoch+1}: train_loss: {train_loss:.4f} train_acc: {train_acc:.4f} | test_loss: {test_loss:.4f} test_acc: {test_acc:.4f}')\n","    print(\"{:0>2}:{:0>2}:{:05.2f}\".format(int(hours),int(minutes),seconds))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ipq4Bl9mM3OL","executionInfo":{"status":"ok","timestamp":1702876858382,"user_tz":-420,"elapsed":86973,"user":{"displayName":"Rahmat Hendrawan","userId":"13136351621992479567"}},"outputId":"d2faf348-1b9c-4c69-be77-9c8df7265fb0"},"execution_count":80,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1: train_loss: 0.4934 train_acc: 0.7992 | test_loss: 0.4660 test_acc: 0.8626\n","00:00:43.56\n","Epoch 2: train_loss: 0.0622 train_acc: 0.9839 | test_loss: 0.6192 test_acc: 0.8454\n","00:00:42.42\n"]}]},{"cell_type":"code","source":["model.device# Prediction on validation set\n","\n","# Put model in evaluation mode\n","model.eval()\n","torch.set_grad_enabled(False)\n","\n","# Tracking variables\n","test_pred = []\n","\n","# Predict\n","for batch in test_dataloader:\n","    # Add batch to GPU\n","    batch = tuple(t.to(device) for t in batch)\n","    # Unpack the inputs from our dataloader\n","    b_input_ids, b_input_mask,_ = batch\n","\n","    # Telling the model not to compute or store gradients, saving memory and\n","    # speeding up prediction\n","    with torch.no_grad():\n","        # Forward pass, calculate logit predictions\n","        outputs = model(b_input_ids, token_type_ids=None,\n","                        attention_mask=b_input_mask)\n","\n","    logits = outputs[0]\n","\n","    # Move logits and labels to CPU\n","    logits = logits.detach().cpu().numpy()\n","\n","    # Store predictions and true labels\n","    test_pred.append(logits)\n","\n","print('    DONE.')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UF09DmhTPLUS","executionInfo":{"status":"ok","timestamp":1702876197643,"user_tz":-420,"elapsed":3051,"user":{"displayName":"Rahmat Hendrawan","userId":"13136351621992479567"}},"outputId":"91de972e-5c16-4378-9cfd-87770ed89710"},"execution_count":49,"outputs":[{"output_type":"stream","name":"stdout","text":["    DONE.\n"]}]},{"cell_type":"code","source":["test_pred = np.concatenate(test_pred, axis=0)\n","test_pred = test_pred.argmax(axis=1)"],"metadata":{"id":"9z1R3YEiPWph","executionInfo":{"status":"ok","timestamp":1702876199026,"user_tz":-420,"elapsed":3,"user":{"displayName":"Rahmat Hendrawan","userId":"13136351621992479567"}}},"execution_count":50,"outputs":[]},{"cell_type":"code","source":["print(classification_report(test_pred,y_test))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wZYQBzCXPpiq","executionInfo":{"status":"ok","timestamp":1702876201040,"user_tz":-420,"elapsed":4,"user":{"displayName":"Rahmat Hendrawan","userId":"13136351621992479567"}},"outputId":"30c8de36-67a1-4521-b2e1-553ccd88ea28"},"execution_count":51,"outputs":[{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.96      0.93      0.94       874\n","           1       0.06      0.40      0.10         5\n","           2       0.49      0.48      0.48        75\n","\n","    accuracy                           0.89       954\n","   macro avg       0.50      0.60      0.51       954\n","weighted avg       0.92      0.89      0.90       954\n","\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"Ek9mazL6TqEF"},"execution_count":null,"outputs":[]}]}